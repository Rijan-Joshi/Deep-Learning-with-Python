{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rijancs/computervision1?scriptVersionId=224460731\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#**Training the MNIST digit on convolutional dataset**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\n\n#Loading the dataset\n(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n\n#Reshaping the data\ntrain_data = train_data.reshape((60000, 28*28)).astype('float32') / 255\ntest_data = test_data.reshape((10000, 28*28)).astype('float32') / 255","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:11:26.421341Z","iopub.execute_input":"2025-02-25T17:11:26.421679Z","iopub.status.idle":"2025-02-25T17:11:26.813896Z","shell.execute_reply.started":"2025-02-25T17:11:26.421656Z","shell.execute_reply":"2025-02-25T17:11:26.812927Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tensorflow import keras\n\nmodel = keras.Sequential([\n    keras.layers.Dense(512, activation = 'relu'),\n    keras.layers.Dense(10, activation = 'softmax')\n])\n\nmodel.compile(optimizer = 'rmsprop', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\nmodel.fit(train_data, train_labels , epochs = 5, batch_size = 64)\n\ntest_loss, test_acc = model.evaluate(test_data, test_labels)\ntest_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:30:58.667019Z","iopub.execute_input":"2025-02-25T17:30:58.667426Z","iopub.status.idle":"2025-02-25T17:31:07.390607Z","shell.execute_reply.started":"2025-02-25T17:30:58.667393Z","shell.execute_reply":"2025-02-25T17:31:07.38988Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.3789\nEpoch 2/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9713 - loss: 0.0985\nEpoch 3/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9821 - loss: 0.0590\nEpoch 4/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9870 - loss: 0.0422\nEpoch 5/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9908 - loss: 0.0297\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0793\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.9807000160217285"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n(train_images, train_targets), (test_images, test_targets) = mnist.load_data()\n\ntrain_images = train_images.reshape((60000,28,28,1)).astype('float32') / 255\ntest_images = test_images.reshape((10000,28,28,1)).astype('float32') / 255\n\n#Building model using Functional API\ninputs = keras.Input((28,28,1))\nx = layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu')(inputs)\nx = layers.MaxPooling2D(pool_size = 2)(x)\nx = layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu')(x)\nx = layers.MaxPooling2D(pool_size = 2)(x)\nx = layers.Conv2D(filters = 128, kernel_size = 3, activation = 'relu')(x)\nx = layers.Flatten()(x)\noutputs = layers.Dense(10, activation = 'softmax')(x)\nmodel = keras.Model(inputs = inputs, outputs = outputs)\n\nmodel.compile(\n    optimizer = 'rmsprop',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel.fit(train_images, train_targets, epochs = 5, batch_size = 64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:28:46.639906Z","iopub.execute_input":"2025-02-25T17:28:46.64036Z","iopub.status.idle":"2025-02-25T17:29:01.728047Z","shell.execute_reply.started":"2025-02-25T17:28:46.640328Z","shell.execute_reply":"2025-02-25T17:29:01.727385Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.3530\nEpoch 2/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0472\nEpoch 3/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0307\nEpoch 4/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0220\nEpoch 5/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0141\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fc75dbe13f0>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_images, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:30:45.160448Z","iopub.execute_input":"2025-02-25T17:30:45.160786Z","iopub.status.idle":"2025-02-25T17:30:46.972585Z","shell.execute_reply.started":"2025-02-25T17:30:45.160762Z","shell.execute_reply":"2025-02-25T17:30:46.971881Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0450\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"test_loss, test_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T17:30:55.00263Z","iopub.execute_input":"2025-02-25T17:30:55.002922Z","iopub.status.idle":"2025-02-25T17:30:55.007906Z","shell.execute_reply.started":"2025-02-25T17:30:55.0029Z","shell.execute_reply":"2025-02-25T17:30:55.007109Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(0.03458518534898758, 0.9896000027656555)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}